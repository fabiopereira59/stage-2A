{"cells":[{"cell_type":"markdown","metadata":{"id":"2pMcPEIkmnVU"},"source":["\u003ccenter\u003e\n","  \u003ch1 style=\"font-family: Arial, sans-serif; font-weight: bold; font-size: 36px; color: #008CBA; text-shadow: 2px 2px #BDBDBD;\"\u003eClassifying bees using Deep Learning\u003c/h1\u003e\n","  \u003ch2 style=\"font-family: Arial, sans-serif; font-weight: bold; font-size: 36px; color: #008CBA; text-shadow: 2px 2px #BDBDBD;\"\u003eFabio PEREIRA DE ARAUJO\u003c/h2\u003e\n","  \u003ch3 style=\"font-family: Arial, sans-serif; font-weight: bold; font-size: 36px; color: #008CBA; text-shadow: 2px 2px #BDBDBD;\"\u003eSecond-year engineering school internship\u003c/h3\u003e\n","\u003c/center\u003e\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22159,"status":"ok","timestamp":1685286287445,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"MorcXQTb22HG","outputId":"e6d0e47c-959e-4c17-8b6a-78762d9f6d9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"fhvvhfOLwb9x"},"source":["## Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3556,"status":"ok","timestamp":1685286294187,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"WDqk-xOpwbY7"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.utils import Sequence\n","import numpy as np\n","import cv2 as cv\n","from tensorflow.keras import regularizers\n","from tensorflow.keras import optimizers"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19820,"status":"ok","timestamp":1685286313990,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"ce0g1Idc08Tt","outputId":"c18c4883-9be1-4e38-a378-06bcac6ecaad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: opencv-python-headless 4.7.0.72\n","Uninstalling opencv-python-headless-4.7.0.72:\n","  Would remove:\n","    /usr/local/lib/python3.10/dist-packages/cv2/*\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless-4.7.0.72.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libavcodec-16a334ab.so.59.37.100\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libavformat-e0b1067c.so.59.27.100\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libavutil-82c407cb.so.57.28.100\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libcrypto-47343492.so.1.1\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libpng16-57e5e0a0.so.16.37.0\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libssl-16e42f2f.so.1.1\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libswresample-d02fa90a.so.4.7.100\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libswscale-9b504c0d.so.6.7.100\n","    /usr/local/lib/python3.10/dist-packages/opencv_python_headless.libs/libvpx-e95aadfe.so.7.1.0\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/fonts/DejaVuSans-Bold.ttf\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/fonts/DejaVuSans-BoldOblique.ttf\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/fonts/DejaVuSans-ExtraLight.ttf\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/fonts/DejaVuSans-Oblique.ttf\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/fonts/DejaVuSans.ttf\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/fonts/DejaVuSansCondensed-Bold.ttf\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/fonts/DejaVuSansCondensed-BoldOblique.ttf\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/fonts/DejaVuSansCondensed-Oblique.ttf\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/fonts/DejaVuSansCondensed.ttf\n","    /usr/local/lib/python3.10/dist-packages/cv2/qt/plugins/platforms/libqxcb.so\n","Proceed (Y/n)? y\n","  Successfully uninstalled opencv-python-headless-4.7.0.72\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python-headless==4.1.2.30 (from versions: 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python-headless==4.1.2.30\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25halbumentations==1.3.0 is successfully installed\n"]}],"source":["!pip uninstall opencv-python-headless==4.5.5.62\n","!pip install opencv-python-headless==4.1.2.30\n","!pip install -q -U albumentations\n","!echo \"$(pip freeze | grep albumentations) is successfully installed\""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1951,"status":"ok","timestamp":1685286315929,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"Hzu0rQSL0-uO"},"outputs":[],"source":["from albumentations import (Compose, Rotate, HorizontalFlip, VerticalFlip, Affine, RandomBrightnessContrast, ChannelShuffle)\n","import albumentations as A"]},{"cell_type":"markdown","metadata":{"id":"pZ7jV9PTwS6F"},"source":["## Variables"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1685286320139,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"La3VNQBUwSRy"},"outputs":[],"source":["IMG_SIZE = 224 #@param\n","BATCH_SIZE = 16 #@param\n","lr = 1e-3 #@param\n","train_path = \"stage-2A/res/cap500/train\" #@param\n","val_path = \"stage-2A/res/cap500/val\" #@param"]},{"cell_type":"markdown","metadata":{"id":"xzZYwhV0Iaww"},"source":["## Téléchargement de la base de données"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16904,"status":"ok","timestamp":1685286342865,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"pjqqzJcoIh-_","outputId":"9936ab14-ec4c-407e-c41f-fe360bdb1930"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'abeilles-cap500'...\n","remote: Enumerating objects: 24902, done.\u001b[K\n","remote: Counting objects: 100% (6150/6150), done.\u001b[K\n","remote: Compressing objects: 100% (6136/6136), done.\u001b[K\n","remote: Total 24902 (delta 11), reused 6150 (delta 11), pack-reused 18752\u001b[K\n","Receiving objects: 100% (24902/24902), 249.57 MiB | 21.36 MiB/s, done.\n","Resolving deltas: 100% (14/14), done.\n","Updating files: 100% (24098/24098), done.\n"]}],"source":["!git clone https://github.com/fabiopereira59/abeilles-cap500"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4267,"status":"ok","timestamp":1685283739674,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"I7Di5BLCIh-_","outputId":"5313e40f-ee2c-4fd4-ff10-9390a01efff6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 14917 files belonging to 71 classes.\n"]}],"source":["# Retrieve datasets for training (train, val)\n","# Shuffle to false to access images from\n","# their path with train_ds.file_paths\n","train_ds = keras.utils.image_dataset_from_directory(\n","    directory=train_path,\n","    labels='inferred',\n","    label_mode='categorical',\n","    shuffle = False,\n","    batch_size=BATCH_SIZE,\n","    image_size=(IMG_SIZE, IMG_SIZE))\n","\n","validation_ds = keras.utils.image_dataset_from_directory(\n","    directory=train_path,\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=BATCH_SIZE,\n","    image_size=(IMG_SIZE, IMG_SIZE))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4755,"status":"ok","timestamp":1685286427528,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"XpPL7p605aM6","outputId":"27573578-9dfe-447d-d53e-4f43d0c4a844"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 14917 files belonging to 71 classes.\n","Found 1832 files belonging to 71 classes.\n"]}],"source":["# Retrieve datasets for training (train, val)\n","# Shuffle to false to access images from\n","# their path with train_ds.file_paths\n","train_ds = keras.utils.image_dataset_from_directory(\n","    directory=\"/content/abeilles-cap500/train\",\n","    labels='inferred',\n","    label_mode='categorical',\n","    shuffle = False,\n","    batch_size=BATCH_SIZE,\n","    image_size=(IMG_SIZE, IMG_SIZE))\n","\n","validation_ds = keras.utils.image_dataset_from_directory(\n","    directory=\"/content/abeilles-cap500/val\",\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=BATCH_SIZE,\n","    image_size=(IMG_SIZE, IMG_SIZE))"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":333,"status":"ok","timestamp":1685287107344,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"VgrOKSfaIh-_"},"outputs":[],"source":["class_names = train_ds.class_names\n","nb_classes = len(class_names)\n","nb_imgs_train = 14917\n","nb_imgs_val = 1932"]},{"cell_type":"markdown","metadata":{"id":"CN1hk3SeoEYJ"},"source":["## Augmentation de données : Sequence et Albumentations"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":345,"status":"ok","timestamp":1685287113846,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"G1H0ApCB35Gn"},"outputs":[],"source":["AUGMENTATIONS_TRAIN = Compose([\n","    Rotate(limit=[0,100], p=0.5),\n","    HorizontalFlip(p=0.5),\n","    VerticalFlip(p=0.5),\n","    Affine(shear=[-45, 45], p=0.5),\n","    RandomBrightnessContrast(p=0.5)\n","])"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1685287114668,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"tEaycO8VhyLH"},"outputs":[],"source":["class AbeillesSequence(Sequence):\n","    # Sequence initialisation with different parameters\n","    def __init__(self, x_train, y_train, batch_size, augmentations):\n","        self.x_train = x_train\n","        self.y_train = y_train\n","        self.classes = class_names\n","        self.batch_size = batch_size\n","        self.augment = augmentations\n","        self.indices1 = np.arange(len(x_train))\n","        np.random.shuffle(self.indices1) # The indices provide access\n","        # data and are randomised at each epoch to vary the composition\n","        # of batches during training\n","\n","    # Function calculating the number of gradient descent steps per epoch\n","    def __len__(self):\n","        return int(np.ceil(x_train.shape[0] / float(self.batch_size)))\n","    \n","    # Apply data augmentation to each image in the batch\n","    def apply_augmentation(self, bx, by):\n","\n","        batch_x = np.zeros((bx.shape[0], IMG_SIZE, IMG_SIZE, 3))\n","        batch_y = by\n","        \n","        for i in range(len(bx)):\n","            class_labels = []\n","            class_id = np.argmax(by[i])\n","            class_labels.append(self.classes[class_id])\n","\n","            # Applying augmentation to images\n","            img = cv.imread(bx[i])\n","            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n","            transformed = self.augment(image=img)\n","            batch_x[i] = transformed['image']\n","      \n","        return batch_x, batch_y\n","\n","    # Function called for each new batch: selection and increase of data\n","    # idx = batch position (idx = 5 =\u003e the 5th batch is taken)\n","    def __getitem__(self, idx):\n","        batch_x = self.x_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n","        batch_y = self.y_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n","           \n","        batch_x, batch_y = self.apply_augmentation(batch_x, batch_y)\n","\n","        # Data normalisation\n","        batch_x = tf.keras.applications.resnet.preprocess_input(batch_x)\n","        \n","        return batch_x, batch_y\n","\n","    # Function called at the end of an epoch; data access indices are randomised\n","    def on_epoch_end(self):\n","        np.random.shuffle(self.indices1)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":7778,"status":"ok","timestamp":1685287149452,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"MQxHTeedPwsn"},"outputs":[],"source":["# Images are stored with paths\n","\n","x_train = np.array(train_ds.file_paths)\n","y_train = np.zeros((nb_imgs_train, nb_classes))\n","\n","ind_data = 0\n","for bx, by in train_ds.as_numpy_iterator():\n","  y_train[ind_data:ind_data+bx.shape[0]] = by\n","  ind_data += bx.shape[0]"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":3467,"status":"ok","timestamp":1685287152908,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"qclVcaJrG1Gn"},"outputs":[],"source":["# Sequence Instantiation\n","train_ds_aug = AbeillesSequence(x_train, y_train, batch_size=16, augmentations=AUGMENTATIONS_TRAIN)\n","\n","# Normalisation of validation data\n","\n","x_val = np.zeros((nb_imgs_val, IMG_SIZE, IMG_SIZE, 3))\n","y_val = np.zeros((nb_imgs_val, nb_classes))\n","\n","ind_data = 0\n","for bx, by in validation_ds.as_numpy_iterator():\n","  x_val[ind_data:ind_data+bx.shape[0]] = bx\n","  y_val[ind_data:ind_data+bx.shape[0]] = by\n","  ind_data += bx.shape[0]\n","\n","x_val = tf.keras.applications.resnet.preprocess_input(x_val)"]},{"cell_type":"markdown","metadata":{"id":"h6MijFSSqNEi"},"source":["## Création du modèle"]},{"cell_type":"markdown","metadata":{"id":"wHrwHiS3Szq3"},"source":["### Poids d'imagenet"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9920,"status":"ok","timestamp":1685287213980,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"cVEsReLqsmGX","outputId":"ee7ee26a-0c84-47e2-8614-cb3354fc8443"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n","171446536/171446536 [==============================] - 5s 0us/step\n"]}],"source":["conv_base = keras.applications.resnet.ResNet101(\n","    include_top=False,\n","    weights='imagenet',\n","    input_tensor=None,\n","    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n","    pooling=None,\n","    classes=nb_classes,\n",")\n","\n","model = keras.Sequential(\n","    [\n","        conv_base,\n","        layers.GlobalAveragePooling2D(),\n","        layers.Dense(nb_classes, kernel_regularizer=regularizers.L2(1e-4), activation='softmax')\n","    ]\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1685287213981,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"8Ouz5O07S8q3","outputId":"35b3dcc8-ba05-48de-89b3-25a154b08efb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet101 (Functional)      (None, 7, 7, 2048)        42658176  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 71)                145479    \n","                                                                 \n","=================================================================\n","Total params: 42,803,655\n","Trainable params: 42,698,311\n","Non-trainable params: 105,344\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"HYD4k8GDtG-G"},"source":["## Hierarchical loss"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":3429,"status":"ok","timestamp":1685287217402,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"vHFsiNjctJsM"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","hierarchie = pd.read_csv(\"/content/drive/MyDrive/ENSEEIHT/2A/Stage 2A/src/training/csv/hierarchie_especes71.csv\")\n","\n","species = hierarchie[\"species\"].unique()\n","nb_species = len(species)\n","\n","genus = list(hierarchie[\"genus\"].unique())\n","nb_genus = len(genus)\n","\n","family = list(hierarchie[\"family\"].unique())\n","nb_family = len(family)\n","\n","subfamily = list(hierarchie[\"subfamily\"].unique())\n","nb_subfamily = len(subfamily)\n","\n","#hierarchie.set_index(\"species\", inplace=True)\n","data = pd.read_csv(\"/content/drive/MyDrive/ENSEEIHT/2A/Stage 2A/src/training/csv/liste_classes_71.csv\")\n","#data.set_index(\"species\", inplace=True)\n","\n","species_to_genus = np.zeros((nb_genus, nb_species))\n","genus_to_subfamily = np.zeros((nb_subfamily, nb_genus))\n","subfamily_to_family = np.zeros((nb_family, nb_subfamily))\n","for i in range(nb_species):\n","  nb_images = data.at[i, \"0\"]\n","  # species -\u003e genus\n","  genus_species = hierarchie.at[i, \"genus\"]\n","  ind_genus = genus.index(genus_species)\n","  species_to_genus[ind_genus, i] = 1\n","\n","  # genus -\u003e subfamily\n","  subfamily_species = hierarchie.at[i, \"subfamily\"]\n","  ind_subfamily = subfamily.index(subfamily_species)\n","  genus_to_subfamily[ind_subfamily, ind_genus] = 1\n","\n","  # subfamily -\u003e family\n","  family_species = hierarchie.at[i, \"family\"]\n","  ind_family = family.index(family_species)\n","  subfamily_to_family[ind_family, ind_subfamily] = 1"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1685287217403,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"tAmdf0ELtSUr"},"outputs":[],"source":["from numpy.ma.core import transpose\n","from keras import backend as K\n","import math\n","import tensorflow as tf\n","\n","# Definition of the loss function\n","def Hierarchicaloss(species_to_genus, genus_to_subfamily, subfamily_to_family, batch_size, alpha=0.1):\n","\n","    def weight(height=1):\n","      return math.exp(-alpha * height)\n","    \n","    def species_loss(y_true, y_pred):\n","      height = 0\n","      return weight(height) * K.categorical_crossentropy(y_true, y_pred)\n","  \n","    def species_to_genus_loss(y_true, y_pred):\n","      height = 1\n","      y_true_genus = K.transpose(tf.raw_ops.MatMul(a=species_to_genus, b=tf.cast(y_true, tf.float64), transpose_b=True))\n","      y_pred_genus = K.transpose(tf.raw_ops.MatMul(a=species_to_genus, b=tf.cast(y_pred, tf.float64), transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_genus, y_pred_genus), y_true_genus, y_pred_genus\n","    \n","    def genus_to_subfamily_loss(y_true, y_pred):\n","      height = 2\n","      y_true_subfamily = K.transpose(tf.raw_ops.MatMul(a=genus_to_subfamily, b=y_true, transpose_b=True))\n","      y_pred_subfamily = K.transpose(tf.raw_ops.MatMul(a=genus_to_subfamily, b=y_pred, transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_subfamily, y_pred_subfamily), y_true_subfamily, y_pred_subfamily\n","    \n","    def subfamily_to_family_loss(y_true, y_pred):\n","      height = 3\n","      y_true_family = K.transpose(tf.raw_ops.MatMul(a=subfamily_to_family, b=y_true, transpose_b=True))\n","      y_pred_family = K.transpose(tf.raw_ops.MatMul(a=subfamily_to_family, b=y_pred, transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_family, y_pred_family)\n","\n","    def HIERARCHICAL_loss(y_true, y_pred):\n","      loss_species = tf.cast(species_loss(y_true, y_pred), tf.float64)\n","      loss_genus, y_true_genus, y_pred_genus = species_to_genus_loss(y_true, y_pred)\n","      loss_subfamily, y_true_subfamily, y_pred_subfamily = genus_to_subfamily_loss(y_true_genus, y_pred_genus)\n","      loss_family = subfamily_to_family_loss(y_true_subfamily, y_pred_subfamily)\n","      return (loss_species + loss_genus + loss_subfamily + loss_family)/batch_size\n","   \n","    # Return a function\n","    return HIERARCHICAL_loss"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1685287217403,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"MEDUO4smtiAS"},"outputs":[],"source":["loss=[Hierarchicaloss(species_to_genus, genus_to_subfamily, subfamily_to_family, batch_size=16, alpha=0.5)]"]},{"cell_type":"markdown","metadata":{"id":"AGrRfh4ZrHM1"},"source":["## Entraînement du modèle"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685287217404,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"IOxq6KpzGb9I"},"outputs":[],"source":["# Ajout de l'optimiseur, de la fonction coût et des métriques\n","model.compile(optimizers.SGD(learning_rate=lr, momentum=0.9), loss=loss, metrics=['categorical_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1685287217404,"user":{"displayName":"Boshi","userId":"08165065872120645038"},"user_tz":-120},"id":"tWhbz7V0Gtjs"},"outputs":[],"source":["# Les callbacks\n","model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=\"/content/poids\",\n","    save_weights_only=True,\n","    monitor='val_categorical_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    verbose=1)\n","\n","#early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n","#    monitor=\"val_categorical_accuracy\",\n","#    min_delta=0.01,\n","#    patience=8,\n","#    verbose=1,\n","#    mode=\"auto\")\n","\n","reduce_lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.1,\n","                              patience=5, min_lr=0.00001, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"0hxLaoBeGxTn"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n"]}],"source":["history = model.fit(train_ds_aug, epochs=150, validation_data = (x_val, y_val), callbacks=[model_checkpoint_cb, reduce_lr_cb])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMDJFH5L5O5FrUv0IvYS3Pj","collapsed_sections":["xzZYwhV0Iaww","T8wS3HAynMlY","CN1hk3SeoEYJ","h6MijFSSqNEi","wHrwHiS3Szq3","34MnJ8YHqXKC","HYD4k8GDtG-G","AGrRfh4ZrHM1"],"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}